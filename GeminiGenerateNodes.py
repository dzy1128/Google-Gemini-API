
# -*- coding: utf-8 -*-
"""
ComfyUI Custom Node: Gemini Generate Content (3-Image) - Multi-Candidate Output

åŠŸèƒ½:
- æ¥æ”¶ 1~3 å¼ å›¾ç‰‡ï¼ˆç¬¬1å¼ å¿…éœ€ï¼Œå¦å¤–2å¼ å¯é€‰ï¼‰ï¼Œå’Œä¸€ä¸ªæ–‡æœ¬ promptã€‚
- è°ƒç”¨ Google AI çš„ genai SDKï¼ˆä¸ç”¨æˆ·ç¤ºä¾‹ä¸€è‡´: from google import genaiï¼‰ï¼Œ
  ä½¿ç”¨æ¨¡å‹ "gemini-2.5-flash-image-preview" è¿›è¡Œå¤šæ¨¡æ€ç”Ÿæˆã€‚
- æ”¯æŒç”Ÿæˆå¤šä¸ªå€™é€‰ç»“æœï¼Œè§£æè¿”å›çš„æ‰€æœ‰å€™é€‰ï¼Œè¾“å‡ºï¼š
  1) IMAGES: ç”Ÿæˆçš„å›¾ç‰‡æ‰¹æ¬¡ï¼ˆæ¥è‡ªæ‰€æœ‰å€™é€‰çš„å›¾ç‰‡ï¼‰ï¼›å¦‚æœæ²¡æœ‰ç”Ÿæˆå›¾ç‰‡åˆ™å›ä¼ è¾“å…¥çš„ç¬¬1å¼ å›¾ç‰‡ã€‚
  2) STRING: åˆå¹¶çš„æ–‡æœ¬è¾“å‡ºï¼ˆæ¥è‡ªæ‰€æœ‰å€™é€‰ï¼‰ã€‚
  3) BOOLEAN: æ˜¯å¦ç”Ÿæˆäº†æ–°å›¾ç‰‡çš„æ ‡è®°ã€‚
  4) INT: ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡ã€‚

å¤šå€™é€‰å¤„ç†ç‰¹æ€§:
- é€šè¿‡ candidate_count å‚æ•°æ§åˆ¶ç”Ÿæˆå€™é€‰æ•°é‡ï¼ˆ1-4ä¸ªï¼‰
- è‡ªåŠ¨æ”¶é›†æ‰€æœ‰å€™é€‰ç»“æœä¸­çš„å›¾ç‰‡å’Œæ–‡æœ¬
- å°†æ‰€æœ‰å€™é€‰çš„å›¾ç‰‡ç»„åˆæˆä¸€ä¸ªComfyUIæ‰¹æ¬¡å¼ é‡
- è‡ªåŠ¨è°ƒæ•´æ‰€æœ‰å›¾ç‰‡åˆ°ç›¸åŒå°ºå¯¸ï¼ˆä½¿ç”¨æœ€å¤§å°ºå¯¸ï¼‰
- æ–‡æœ¬è¾“å‡ºä¼šæ ‡æ³¨æ¥è‡ªå“ªä¸ªå€™é€‰ï¼ˆå½“æœ‰å¤šä¸ªå€™é€‰æ—¶ï¼‰
- è¿”å›å›¾ç‰‡æ•°é‡ä¿¡æ¯ï¼Œä¾¿äºåç»­å¤„ç†

å€™é€‰æ•°é‡è¯´æ˜:
- candidate_count=1: ç”Ÿæˆ1ä¸ªå€™é€‰ç»“æœï¼ˆé»˜è®¤ï¼‰
- candidate_count=2-4: ç”Ÿæˆå¤šä¸ªå€™é€‰ç»“æœï¼Œå¢åŠ å›¾ç‰‡å¤šæ ·æ€§

ä¾èµ–:
- pip install google-genai Pillow numpy torch
- éœ€é…ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡ã€‚

å®‰è£…:
- å°†æœ¬æ–‡ä»¶æ”¾å…¥ ComfyUI/custom_nodes/ ç›®å½•ä¸‹ï¼Œé‡å¯ ComfyUIã€‚

æ³¨æ„:
- æœ¬èŠ‚ç‚¹ä»…å–æ¯ä¸ª IMAGE è¾“å…¥çš„ batch ç¬¬ 0 å¼ è¿›è¡Œå¤„ç†ã€‚
- è¾“å‡ºçš„å›¾ç‰‡æ‰¹æ¬¡ä¸­ï¼Œæ‰€æœ‰å›¾ç‰‡éƒ½ä¼šè¢«è°ƒæ•´åˆ°ç›¸åŒå°ºå¯¸ä»¥ä¿è¯å¼ é‡ä¸€è‡´æ€§ã€‚
- æ›´å¤šå€™é€‰æ•°é‡ä¼šæ¶ˆè€—æ›´å¤šAPIé…é¢ï¼Œè¯·æ ¹æ®éœ€è¦è°ƒæ•´ã€‚
- APIè°ƒç”¨: client.models.generate_content(model=..., contents=[...], generation_config={"candidate_count": N})ã€‚
"""

import os
import base64
import random
import requests
import json
from io import BytesIO

import numpy as np
import torch
from PIL import Image

try:
    from google import genai
except Exception as e:
    genai = None

try:
    from openai import OpenAI
except Exception as e:
    OpenAI = None


def _comfy_image_to_pil(img_tensor):
    """å°† ComfyUI çš„ IMAGE (tensor, [B,H,W,C], float32, 0..1) è½¬ä¸ºå•å¼  PIL.Imageã€‚
    ä»…å–æ‰¹æ¬¡çš„ç¬¬ 0 å¼ ã€‚
    """
    if isinstance(img_tensor, torch.Tensor):
        arr = img_tensor[0].detach().cpu().numpy()
    else:
        # å…¼å®¹ numpy è¾“å…¥
        arr = np.asarray(img_tensor)[0]
    arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)
    # åªä¿ç•™å‰3é€šé“
    if arr.ndim == 3 and arr.shape[2] == 4:
        arr = arr[:, :, :3]
    if arr.ndim == 2:
        arr = np.stack([arr] * 3, axis=-1)
    return Image.fromarray(arr)


def _pil_to_comfy_image(pil_img):
    """å°† PIL.Image è½¬ä¸º ComfyUI çš„ IMAGE tensor ([1,H,W,3], float32, 0..1)ã€‚"""
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    arr = np.array(pil_img).astype(np.float32) / 255.0
    if arr.ndim == 2:
        arr = np.stack([arr] * 3, axis=-1)
    if arr.shape[2] > 3:
        arr = arr[:, :, :3]
    tensor = torch.from_numpy(arr)[None, ...]
    return tensor


def _pil_list_to_comfy_images(pil_list):
    """å°† PIL.Image åˆ—è¡¨è½¬ä¸º ComfyUI çš„ IMAGE tensor ([N,H,W,3], float32, 0..1)ã€‚"""
    if not pil_list:
        return None
    
    # è½¬æ¢æ‰€æœ‰å›¾ç‰‡å¹¶æ”¶é›†å°ºå¯¸ä¿¡æ¯
    arrays = []
    max_height = 0
    max_width = 0
    
    for pil_img in pil_list:
        if pil_img.mode != "RGB":
            pil_img = pil_img.convert("RGB")
        arr = np.array(pil_img).astype(np.float32) / 255.0
        if arr.ndim == 2:
            arr = np.stack([arr] * 3, axis=-1)
        if arr.shape[2] > 3:
            arr = arr[:, :, :3]
        
        arrays.append(arr)
        max_height = max(max_height, arr.shape[0])
        max_width = max(max_width, arr.shape[1])
    
    # å°†æ‰€æœ‰å›¾ç‰‡è°ƒæ•´åˆ°ç›¸åŒå°ºå¯¸ï¼ˆä½¿ç”¨æœ€å¤§å°ºå¯¸ï¼‰
    normalized_arrays = []
    for arr in arrays:
        if arr.shape[0] != max_height or arr.shape[1] != max_width:
            # å°†æ•°ç»„è½¬å›PILå›¾ç‰‡è¿›è¡Œå°ºå¯¸è°ƒæ•´
            temp_pil = Image.fromarray((arr * 255.0).astype(np.uint8))
            temp_pil = temp_pil.resize((max_width, max_height), Image.Resampling.LANCZOS)
            arr = np.array(temp_pil).astype(np.float32) / 255.0
        normalized_arrays.append(arr)
    
    # å †å æˆæ‰¹æ¬¡å¼ é‡
    batch_tensor = torch.from_numpy(np.stack(normalized_arrays, axis=0))
    return batch_tensor


def _pil_to_base64(pil_img, format="JPEG"):
    """å°† PIL.Image è½¬æ¢ä¸º base64 ç¼–ç å­—ç¬¦ä¸²ã€‚"""
    buffer = BytesIO()
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    pil_img.save(buffer, format=format)
    img_data = buffer.getvalue()
    return base64.b64encode(img_data).decode('utf-8')


class GeminiGenerate:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "Generate an image of a cute cat eating a nano-banana in a fancy restaurant under the gemini constellation. Create the image, don't just describe it."
                }),
                "image1": ("IMAGE", {}),  # å¿…å¡«
                "seed": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 2147483647,  # INT32 æœ€å¤§å€¼ï¼Œä¸APIå…¼å®¹
                    "step": 1
                }),
            },
            "optional": {
                "image2": ("IMAGE", {}),  # å¯é€‰
                "image3": ("IMAGE", {}),  # å¯é€‰
                "candidate_count": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå€™é€‰å›¾ç‰‡çš„æ•°é‡ï¼ˆ1-4å¼ ï¼‰"
                }),
                "model_name": ("STRING", {"default": "gemini-2.5-flash-image-preview"}),
                "max_retries": ("INT", {
                    "default": 2,
                    "min": 0,
                    "max": 5,
                    "step": 1
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "BOOLEAN", "INT")
    RETURN_NAMES = ("images", "text", "image_generated", "image_count")
    FUNCTION = "generate"
    CATEGORY = "Google/GenAI"
    OUTPUT_NODE = False

    def _get_client(self):
        if genai is None:
            raise RuntimeError("google-genai SDK not installed. Please run: pip install google-genai")
        key = os.getenv("GOOGLE_API_KEY", "").strip()
        if not key:
            raise RuntimeError("GOOGLE_API_KEY environment variable is required but not set")
        # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ä½¿ç”¨é»˜è®¤å®¢æˆ·ç«¯åˆ›å»ºæ–¹å¼
        # ç¯å¢ƒå˜é‡ä¼šè‡ªåŠ¨è¢«SDKä½¿ç”¨
        return genai.Client()

    def generate(self, prompt, image1, seed, image2=None, image3=None, candidate_count=1, model_name="gemini-2.5-flash-image-preview", max_retries=2):
        # æ„é€  contents: [prompt, image1, (image2?), (image3?)]
        # seed å‚æ•°åªç”¨äº ComfyUI èŠ‚ç‚¹ï¼Œä¸ä¼ é€’ç»™ Gemini API
        contents = [str(prompt)]

        try:
            pil1 = _comfy_image_to_pil(image1)
            contents.append(pil1)
            if image2 is not None:
                contents.append(_comfy_image_to_pil(image2))
            if image3 is not None:
                contents.append(_comfy_image_to_pil(image3))
        except Exception as e:
            # è½¬æ¢å¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯æ–‡æœ¬å’ŒåŸå›¾
            return image1, f"[Gemini Node] Failed to convert input images: {e}", False, 1

        # API è°ƒç”¨é‡è¯•é€»è¾‘ - æ”¯æŒå¤šæ¬¡è°ƒç”¨è·å¾—å¤šå€™é€‰
        client = None
        responses = []  # å­˜å‚¨æ‰€æœ‰å“åº”
        last_error = None
        
        # å°è¯•è·å–å¤šä¸ªå€™é€‰ç»“æœ
        for candidate_idx in range(candidate_count):
            resp = None
            for attempt in range(max_retries + 1):
                try:
                    if client is None:
                        client = self._get_client()
                    
                    # å°è¯•ä¸åŒçš„å‚æ•°ä¼ é€’æ–¹å¼
                    try:
                        # æ–¹æ³•1: ç›´æ¥ä¼ é€’candidate_countå‚æ•°
                        resp = client.models.generate_content(
                            model=model_name,
                            contents=contents,
                            candidate_count=candidate_count,
                        )
                        # å¦‚æœæˆåŠŸä¸”è¿”å›å¤šä¸ªå€™é€‰ï¼Œç›´æ¥ä½¿ç”¨è¿™ä¸ªå“åº”
                        if hasattr(resp, 'candidates') and len(resp.candidates) >= candidate_count:
                            responses = [resp]  # ä½¿ç”¨è¿™ä¸ªåŒ…å«å¤šå€™é€‰çš„å“åº”
                            break  # é€€å‡ºå€™é€‰å¾ªç¯
                    except TypeError as e1:
                        try:
                            # æ–¹æ³•2: ä½¿ç”¨generation_configå­—å…¸
                            generation_config = {
                                "candidate_count": candidate_count,
                            }
                            resp = client.models.generate_content(
                                model=model_name,
                                contents=contents,
                                generation_config=generation_config,
                            )
                            # å¦‚æœæˆåŠŸä¸”è¿”å›å¤šä¸ªå€™é€‰ï¼Œç›´æ¥ä½¿ç”¨è¿™ä¸ªå“åº”
                            if hasattr(resp, 'candidates') and len(resp.candidates) >= candidate_count:
                                responses = [resp]  # ä½¿ç”¨è¿™ä¸ªåŒ…å«å¤šå€™é€‰çš„å“åº”
                                break  # é€€å‡ºå€™é€‰å¾ªç¯
                        except TypeError as e2:
                            # æ–¹æ³•3: å›é€€åˆ°å•æ¬¡è°ƒç”¨
                            if candidate_idx == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡è­¦å‘Š
                                print(f"[Gemini Node] Warning: APIä¸æ”¯æŒcandidate_countå‚æ•°ï¼Œå°†é€šè¿‡å¤šæ¬¡è°ƒç”¨è·å¾—{candidate_count}ä¸ªç»“æœ")
                            resp = client.models.generate_content(
                                model=model_name,
                                contents=contents,
                            )
                    break  # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    last_error = e
                    error_str = str(e)
                    
                    # å¯¹äºæŸäº›é”™è¯¯ï¼Œä¸è¿›è¡Œé‡è¯•
                    if ("400" in error_str or "FAILED_PRECONDITION" in error_str or 
                        "User location is not supported" in error_str or
                        "RESOURCE_EXHAUSTED" in error_str or
                        "PROHIBITED_CONTENT" in error_str):
                        break
                    
                    # å¯¹äºå¯é‡è¯•çš„é”™è¯¯ï¼ˆå¦‚ 500ï¼‰ï¼Œç­‰å¾…åé‡è¯•
                    if attempt < max_retries:
                        import time
                        wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š2ç§’, 4ç§’, 6ç§’...
                        time.sleep(wait_time)
            
            # å¦‚æœè·å¾—äº†å“åº”ï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
            if resp is not None:
                responses.append(resp)
                # å¦‚æœè¿™ä¸ªå“åº”åŒ…å«å¤šä¸ªå€™é€‰ï¼Œå°±ä¸éœ€è¦ç»§ç»­å¾ªç¯äº†
                if hasattr(resp, 'candidates') and len(resp.candidates) > 1:
                    break
            else:
                # å¦‚æœè¿™æ¬¡è°ƒç”¨å¤±è´¥ï¼Œåœæ­¢å°è¯•æ›´å¤šå€™é€‰
                break
        
        # å¤„ç†æœ€ç»ˆå¤±è´¥çš„æƒ…å†µ
        if not responses:
            error_str = str(last_error) if last_error else "Unknown error"
            
            # æ£€æŸ¥å…·ä½“çš„é”™è¯¯ç±»å‹å¹¶æä¾›ç›¸åº”çš„å»ºè®®
            if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                return image1, f"[Gemini Node] APIé…é¢å·²ç”¨å®Œï¼Œè¯·ç¨åé‡è¯•æˆ–å‡çº§è®¡åˆ’ã€‚", False, 1
            elif "400" in error_str and "User location is not supported" in error_str:
                return image1, f"[Gemini Node] åœ°ç†ä½ç½®é™åˆ¶ï¼šä½ æ‰€åœ¨çš„åœ°åŒºä¸æ”¯æŒä½¿ç”¨ Gemini APIã€‚è¯·æ£€æŸ¥ä»£ç†è®¾ç½®ã€‚", False, 1
            elif "PROHIBITED_CONTENT" in error_str:
                return image1, f"[Gemini Node] å†…å®¹è¢«æ‹’ç»ï¼šæ¨¡å‹è®¤ä¸ºè¯·æ±‚åŒ…å«ç¦æ­¢çš„å†…å®¹ã€‚è¯·å°è¯•ä¿®æ”¹æç¤ºè¯æˆ–å›¾åƒã€‚", False, 1
            elif "500" in error_str or "INTERNAL" in error_str:
                return image1, f"[Gemini Node] Google æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ (500)ï¼Œå·²é‡è¯• {max_retries} æ¬¡ä»å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚", False, 1
            elif "503" in error_str or "SERVICE_UNAVAILABLE" in error_str:
                return image1, f"[Gemini Node] æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ (503)ï¼Œå·²é‡è¯• {max_retries} æ¬¡ä»å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚", False, 1
            elif "FAILED_PRECONDITION" in error_str:
                return image1, f"[Gemini Node] API ä½¿ç”¨æ¡ä»¶ä¸æ»¡è¶³ï¼Œå¯èƒ½æ˜¯åœ°ç†ä½ç½®é™åˆ¶æˆ–å…¶ä»–æ¡ä»¶é—®é¢˜ã€‚", False, 1
            else:
                return image1, f"[Gemini Node] API call failed after {max_retries + 1} attempts: {last_error}", False, 1

        texts = []
        generated_images = []  # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡
        image_generated = False

        try:
            # å®‰å…¨åœ°è§£ææ‰€æœ‰å“åº”
            total_candidates = 0
            for resp_idx, resp in enumerate(responses):
                # æ£€æŸ¥å“åº”ç»“æ„
                if not hasattr(resp, 'candidates') or not resp.candidates:
                    texts.append(f"[å“åº” {resp_idx + 1}] API è¿”å›ç©ºå“åº”ï¼Œæ²¡æœ‰ç”Ÿæˆå†…å®¹")
                    continue
                
                # éå†è¿™ä¸ªå“åº”ä¸­çš„æ‰€æœ‰å€™é€‰ç»“æœ
                for candidate_idx, candidate in enumerate(resp.candidates):
                    total_candidates += 1
                    # å½“æœ‰å¤šä¸ªå“åº”æˆ–å¤šä¸ªå€™é€‰æ—¶æ˜¾ç¤ºæ ‡è¯†
                    if len(responses) > 1 or len(resp.candidates) > 1:
                        candidate_prefix = f"[å€™é€‰ {total_candidates}] "
                    else:
                        candidate_prefix = ""
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ finish_reasonï¼Œè¿™èƒ½å‘Šè¯‰æˆ‘ä»¬ä¸ºä»€ä¹ˆæ²¡æœ‰å†…å®¹
                    if hasattr(candidate, 'finish_reason') and candidate.finish_reason:
                        finish_reason = str(candidate.finish_reason)
                        
                        if 'PROHIBITED_CONTENT' in finish_reason:
                            texts.append(f"{candidate_prefix}å†…å®¹è¢«æ‹’ç»ï¼šæ¨¡å‹è®¤ä¸ºè¯·æ±‚åŒ…å«ç¦æ­¢çš„å†…å®¹ã€‚")
                        elif 'SAFETY' in finish_reason:
                            texts.append(f"{candidate_prefix}å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼šè¯·æ±‚è§¦å‘äº†å®‰å…¨è¿‡æ»¤å™¨ã€‚")
                        elif 'MAX_TOKENS' in finish_reason:
                            texts.append(f"{candidate_prefix}è¾¾åˆ°æœ€å¤§ token é™åˆ¶ï¼Œå“åº”è¢«æˆªæ–­ã€‚")
                        elif 'STOP' in finish_reason:
                            pass  # æ­£å¸¸å®Œæˆï¼Œç»§ç»­å¤„ç†å†…å®¹
                        else:
                            texts.append(f"{candidate_prefix}ç”Ÿæˆå› æœªçŸ¥åŸå› åœæ­¢ï¼š{finish_reason}")
                    
                    # æ£€æŸ¥ content æ˜¯å¦å­˜åœ¨
                    if not hasattr(candidate, 'content') or candidate.content is None:
                        if total_candidates == 1 and not texts:  # åªä¸ºç¬¬ä¸€ä¸ªå€™é€‰æ·»åŠ é”™è¯¯ä¿¡æ¯
                            texts.append(f"{candidate_prefix}API å“åº”ä¸­æ²¡æœ‰å†…å®¹æ•°æ®")
                    else:
                        content = candidate.content
                        
                        # æ£€æŸ¥ parts æ˜¯å¦å­˜åœ¨
                        if not hasattr(content, 'parts') or not content.parts:
                            texts.append(f"{candidate_prefix}å“åº”å†…å®¹ä¸ºç©º")
                        else:
                            parts = content.parts
                            
                            for part in parts:
                                if part.text is not None:
                                    text_with_prefix = f"{candidate_prefix}{part.text}" if candidate_prefix else part.text
                                    texts.append(text_with_prefix)
                                elif part.inline_data is not None:
                                    try:
                                        pil = Image.open(BytesIO(part.inline_data.data))
                                        generated_images.append(pil)
                                        image_generated = True
                                    except Exception as img_e:
                                        texts.append(f"{candidate_prefix}Failed to process generated image: {img_e}")
                
        except Exception as e:
            texts.append(f"[Gemini Node] Failed to parse response: {e}")

        # å¤„ç†å›¾ç‰‡è¾“å‡º
        if generated_images:
            # å¦‚æœæœ‰ç”Ÿæˆçš„å›¾ç‰‡ï¼Œè½¬æ¢ä¸ºComfyUIæ ¼å¼
            out_tensor = _pil_list_to_comfy_images(generated_images)
            image_count = len(generated_images)
        else:
            # æœªç”Ÿæˆå›¾ç‰‡åˆ™å›ä¼ è¾“å…¥çš„ç¬¬1å¼ 
            out_tensor = image1
            image_generated = False
            image_count = 1

        text_out = "\n".join([t for t in texts if t])
        return out_tensor, text_out, image_generated, image_count


class OpenAIGeminiGenerate:
    """
    ComfyUI Custom Node: OpenAI å…¼å®¹æ ¼å¼çš„ Gemini è§†è§‰ç†è§£èŠ‚ç‚¹ï¼ˆå¤šå›¾ç‰‡æ”¯æŒï¼‰
    
    åŠŸèƒ½:
    - é€šè¿‡ OpenAI å…¼å®¹çš„ API æ¥å£è°ƒç”¨ Gemini è§†è§‰æ¨¡å‹
    - æ”¯æŒå¤šå¼ å›¾ç‰‡è¾“å…¥ï¼šç¬¬1å¼ å¿…é€‰ï¼Œç¬¬2ã€3å¼ å¯é€‰
    - å›¾ç‰‡è‡ªåŠ¨è½¬æ¢ä¸º base64 ç¼–ç 
    - ä»ç¯å¢ƒå˜é‡è·å– API Key
    - å¿…éœ€è®¾ç½® seed å€¼ï¼ˆèŒƒå›´ï¼š0 åˆ° 2147483647ï¼ŒINT32 æ ¼å¼ï¼‰
    - é»˜è®¤ä½¿ç”¨ gemini-2.5-flash-image-previewï¼ˆè§†è§‰ç†è§£æ¨¡å‹ï¼‰
    - æ”¯æŒ reasoning_content è¾“å‡ºï¼ˆæ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆåˆ†ç¦»ï¼‰
    
    æ³¨æ„:
    - gemini-2.5-flash-image-preview æ˜¯è§†è§‰ç†è§£æ¨¡å‹ï¼Œä¸ç”Ÿæˆæ–°å›¾ç‰‡
    - ä¸»è¦ç”¨äºåˆ†æå’Œç†è§£è¾“å…¥çš„å›¾ç‰‡å†…å®¹
    - å¦‚éœ€å›¾ç‰‡ç”Ÿæˆï¼Œè¯·ä½¿ç”¨æ”¯æŒå›¾ç‰‡ç”Ÿæˆçš„æ¨¡å‹ï¼ˆå¦‚ dall-e-3ï¼‰
    
    è¾“å…¥:
    - image1: ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå¿…é€‰ï¼‰
    - image2: ç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
    - image3: ç¬¬ä¸‰å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
    
    ä¾èµ–:
    - pip install openai Pillow numpy torch
    - éœ€é…ç½®ç¯å¢ƒå˜é‡ï¼šOPENAI_API_KEY æˆ– DEEPSEEK_API_KEY
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "è¯·è¯¦ç»†åˆ†æè¿™äº›å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š1. å›¾ç‰‡ä¸­çš„ä¸»è¦ç‰©ä½“å’Œåœºæ™¯ 2. é¢œè‰²ã€é£æ ¼å’Œæ„å›¾ç‰¹ç‚¹ 3. å¯èƒ½çš„ç”¨é€”æˆ–èƒŒæ™¯ä¿¡æ¯ã€‚"
                }),
                "image1": ("IMAGE", {}),  # ç¬¬ä¸€å¼ å›¾ç‰‡å¿…é€‰
                "seed": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 2147483647,  # INT32 æœ€å¤§å€¼
                    "step": 1,
                    "tooltip": "éšæœºç§å­ï¼Œæœ€å°å€¼ä¸º0ï¼Œæœ€å¤§å€¼ä¸º2147483647 (INT32èŒƒå›´)"
                }),
                "model_name": ("STRING", {
                    "default": "gemini-2.5-flash-image-preview",
                    "tooltip": "å¸¸ç”¨æ¨¡å‹åç§°: gemini-2.5-flash-image-preview, gemini-pro-vision, gpt-4-vision-preview, gpt-4o"
                }),
                "api_key_env": (["OPENAI_API_KEY", "DEEPSEEK_API_KEY"], {
                    "default": "DEEPSEEK_API_KEY"
                }),
                "base_url": ("STRING", {
                    "default": "https://www.chataiapi.com/v1"
                }),
            },
            "optional": {
                "image2": ("IMAGE", {}),  # ç¬¬äºŒå¼ å›¾ç‰‡å¯é€‰
                "image3": ("IMAGE", {}),  # ç¬¬ä¸‰å¼ å›¾ç‰‡å¯é€‰
                "max_retries": ("INT", {
                    "default": 2,
                    "min": 0,
                    "max": 5,
                    "step": 1
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "BOOLEAN")
    RETURN_NAMES = ("images", "reasoning", "final_answer", "image_generated")
    FUNCTION = "generate"
    CATEGORY = "Google/GenAI"
    OUTPUT_NODE = False

    def _get_client(self, api_key_env, base_url):
        """è·å– OpenAI å®¢æˆ·ç«¯"""
        if OpenAI is None:
            raise RuntimeError("openai SDK not installed. Please run: pip install openai")
        
        # ä»ç¯å¢ƒå˜é‡è·å– API Key
        api_key = os.getenv(api_key_env, "").strip()
        if not api_key:
            raise RuntimeError(f"{api_key_env} environment variable is required but not set")
        
        return OpenAI(
            api_key=api_key,
            base_url=base_url
        )

    def generate(self, prompt, image1, seed, model_name, api_key_env="DEEPSEEK_API_KEY", 
                 base_url="https://www.chataiapi.com/v1", image2=None, image3=None, max_retries=2):
        
        # éªŒè¯ seed å€¼èŒƒå›´ï¼ˆAPI è¦æ±‚ INT32 èŒƒå›´ï¼‰
        if seed < 0 or seed > 2147483647:
            return image1, "", f"[OpenAI Gemini Node] Seed å€¼å¿…é¡»åœ¨ 0 åˆ° 2147483647 èŒƒå›´å†…ï¼Œå½“å‰å€¼: {seed}", False
        
        print(f"[DEBUG] å¼€å§‹å¤„ç†è¯·æ±‚ - æ¨¡å‹: {model_name}")
        print(f"[DEBUG] APIé…ç½® - ç¯å¢ƒå˜é‡: {api_key_env}, åŸºç¡€URL: {base_url}")
        
        try:
            # å¤„ç†ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå¿…é€‰ï¼‰
            pil_img1 = _comfy_image_to_pil(image1)
            base64_img1 = _pil_to_base64(pil_img1)
            
            # æ„å»ºå†…å®¹åˆ—è¡¨ï¼Œä»æ–‡æœ¬å¼€å§‹
            content_list = [{"type": "text", "text": str(prompt)}]
            
            # æ·»åŠ ç¬¬ä¸€å¼ å›¾ç‰‡
            content_list.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_img1}"
                }
            })
            
            # å¤„ç†ç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
            if image2 is not None:
                pil_img2 = _comfy_image_to_pil(image2)
                base64_img2 = _pil_to_base64(pil_img2)
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_img2}"
                    }
                })
            
            # å¤„ç†ç¬¬ä¸‰å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
            if image3 is not None:
                pil_img3 = _comfy_image_to_pil(image3)
                base64_img3 = _pil_to_base64(pil_img3)
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_img3}"
                    }
                })
            
        except Exception as e:
            return image1, "", f"[OpenAI Gemini Node] Failed to process input images: {e}", False

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": content_list
            }
        ]

        # API è°ƒç”¨é‡è¯•é€»è¾‘
        client = None
        last_error = None
        
        for attempt in range(max_retries + 1):
            try:
                if client is None:
                    client = self._get_client(api_key_env, base_url)
                
                # è°ƒç”¨ API
                print(f"[DEBUG] è°ƒç”¨API - æ¨¡å‹: {model_name}, seed: {seed}")
                print(f"[DEBUG] æ¶ˆæ¯æ•°é‡: {len(messages)}, å†…å®¹é¡¹æ•°é‡: {len(messages[0]['content'])}")
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    seed=seed
                )
                
                print(f"[DEBUG] APIè°ƒç”¨æˆåŠŸï¼Œå“åº”ç±»å‹: {type(response)}")
                
                # è§£æå“åº”
                if not response.choices:
                    return image1, "", "[OpenAI Gemini Node] API è¿”å›ç©ºå“åº”", False
                
                print(f"[DEBUG] å“åº”åŒ…å« {len(response.choices)} ä¸ªé€‰æ‹©")
                
                choice = response.choices[0]
                message = choice.message
                
                print(f"[DEBUG] Message å¯¹è±¡å±æ€§: {[attr for attr in dir(message) if not attr.startswith('_')]}")
                print(f"[DEBUG] Message content: {getattr(message, 'content', 'NO CONTENT')}")
                print(f"[DEBUG] Message reasoning_content: {getattr(message, 'reasoning_content', 'NO REASONING')}")
                
                # æå– reasoning_content å’Œ content
                reasoning_content = ""
                final_answer = ""
                
                if hasattr(message, 'reasoning_content') and message.reasoning_content:
                    reasoning_content = message.reasoning_content
                    print(f"[DEBUG] æ‰¾åˆ° reasoning_content: {len(reasoning_content)} å­—ç¬¦")
                else:
                    print(f"[DEBUG] æ²¡æœ‰æ‰¾åˆ° reasoning_content")
                
                if hasattr(message, 'content') and message.content:
                    final_answer = message.content
                    print(f"[DEBUG] æ‰¾åˆ° content: {len(final_answer)} å­—ç¬¦")
                else:
                    print(f"[DEBUG] æ²¡æœ‰æ‰¾åˆ° content")
                
                # å°è¯•è·å–åŸå§‹å“åº”çš„å®Œæ•´ä¿¡æ¯
                print(f"[DEBUG] å®Œæ•´å“åº”å†…å®¹é¢„è§ˆ: {str(response)[:500]}...")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆçš„å›¾ç‰‡
                generated_images = []
                image_generated = False
                
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾ç‰‡ç”Ÿæˆ
                is_image_generation_model = any(keyword in model_name.lower() for keyword in [
                    'dall-e', 'dalle', 'midjourney', 'stable-diffusion', 'image-gen'
                ])
                
                if is_image_generation_model:
                    # å¯¹äºå›¾ç‰‡ç”Ÿæˆæ¨¡å‹ï¼Œæ£€æŸ¥å“åº”ä¸­çš„å›¾ç‰‡æ•°æ®
                    if hasattr(response, 'data') and response.data:
                        print(f"[DEBUG] Found {len(response.data)} images in response")
                        for i, item in enumerate(response.data):
                            try:
                                if hasattr(item, 'b64_json') and item.b64_json:
                                    img_data = base64.b64decode(item.b64_json)
                                    pil_img = Image.open(BytesIO(img_data))
                                    generated_images.append(pil_img)
                                elif hasattr(item, 'url') and item.url:
                                    print(f"[DEBUG] Image URL: {item.url}")
                                    # å¯ä»¥æ·»åŠ ä¸‹è½½URLå›¾ç‰‡çš„é€»è¾‘
                            except Exception as img_e:
                                print(f"[DEBUG] Failed to process image {i}: {img_e}")
                    
                    image_generated = len(generated_images) > 0
                else:
                    # å¯¹äºè§†è§‰ç†è§£æ¨¡å‹ï¼ˆå¦‚ Geminiï¼‰ï¼Œä¸æœŸæœ›ç”Ÿæˆå›¾ç‰‡
                    print(f"[INFO] æ¨¡å‹ {model_name} æ˜¯è§†è§‰ç†è§£æ¨¡å‹ï¼Œä¸ç”Ÿæˆæ–°å›¾ç‰‡")
                    image_generated = False
                
                if generated_images:
                    out_tensor = _pil_list_to_comfy_images(generated_images)
                    image_generated = True
                else:
                    # æœªç”Ÿæˆå›¾ç‰‡åˆ™å›ä¼ ç¬¬ä¸€å¼ è¾“å…¥å›¾ç‰‡
                    out_tensor = image1
                    image_generated = False
                
                # å¦‚æœæ²¡æœ‰è·å¾—ä»»ä½•å†…å®¹ï¼Œè¿”å›è°ƒè¯•ä¿¡æ¯
                if not reasoning_content and not final_answer:
                    debug_info = f"[è°ƒè¯•ä¿¡æ¯] APIè°ƒç”¨æˆåŠŸä½†æœªè¿”å›å†…å®¹ã€‚æ¨¡å‹: {model_name}, å“åº”é€‰æ‹©æ•°: {len(response.choices)}"
                    return out_tensor, debug_info, "APIå“åº”ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°å’ŒAPIé…ç½®", image_generated
                
                return out_tensor, reasoning_content, final_answer, image_generated
                
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # å¯¹äºæŸäº›é”™è¯¯ï¼Œä¸è¿›è¡Œé‡è¯•
                if any(keyword in error_str for keyword in [
                    "400", "401", "403", "FAILED_PRECONDITION", 
                    "User location is not supported", "PROHIBITED_CONTENT"
                ]):
                    break
                
                # å¯¹äºå¯é‡è¯•çš„é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                if attempt < max_retries:
                    import time
                    wait_time = (attempt + 1) * 2
                    time.sleep(wait_time)
        
        # å¤„ç†æœ€ç»ˆå¤±è´¥
        error_str = str(last_error) if last_error else "Unknown error"
        
        if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
            error_msg = "[OpenAI Gemini Node] APIé…é¢å·²ç”¨å®Œï¼Œè¯·ç¨åé‡è¯•æˆ–å‡çº§è®¡åˆ’ã€‚"
        elif "401" in error_str:
            error_msg = "[OpenAI Gemini Node] API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®ã€‚"
        elif "400" in error_str and "User location is not supported" in error_str:
            error_msg = "[OpenAI Gemini Node] åœ°ç†ä½ç½®é™åˆ¶ï¼šä½ æ‰€åœ¨çš„åœ°åŒºä¸æ”¯æŒä½¿ç”¨æ­¤ APIã€‚"
        elif "PROHIBITED_CONTENT" in error_str:
            error_msg = "[OpenAI Gemini Node] å†…å®¹è¢«æ‹’ç»ï¼šæ¨¡å‹è®¤ä¸ºè¯·æ±‚åŒ…å«ç¦æ­¢çš„å†…å®¹ã€‚"
        else:
            error_msg = f"[OpenAI Gemini Node] API call failed: {last_error}"
        
        return image1, "", error_msg, False


class GoogleImagenGenerate:
    """
    ComfyUI Custom Node: Google Gemini å›¾ç‰‡ç¼–è¾‘ç”ŸæˆèŠ‚ç‚¹
    
    åŠŸèƒ½:
    - ä½¿ç”¨ Google åŸç”Ÿ API è°ƒç”¨ Gemini æ¨¡å‹è¿›è¡Œå›¾ç‰‡ç¼–è¾‘å’Œç”Ÿæˆ
    - æ”¯æŒå¤šå¼ å›¾ç‰‡è¾“å…¥ï¼šç¬¬1å¼ å¿…é€‰ï¼Œç¬¬2-5å¼ å¯é€‰
    - æ”¯æŒåŸºäºè¾“å…¥å›¾ç‰‡è¿›è¡Œç¼–è¾‘ã€é£æ ¼è½¬æ¢ã€å†…å®¹ä¿®æ”¹
    - ä»ç¯å¢ƒå˜é‡è·å– Google API Key
    - æ”¯æŒå¤šç§å›¾ç‰‡å°ºå¯¸å’Œæ•°é‡é…ç½®
    - æ”¯æŒ seed æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§
    
    å›¾ç‰‡ç¼–è¾‘èƒ½åŠ›:
    - é£æ ¼è½¬æ¢ï¼šå°†è¾“å…¥å›¾ç‰‡è½¬æ¢ä¸ºä¸åŒè‰ºæœ¯é£æ ¼
    - å†…å®¹ç¼–è¾‘ï¼šä¿®æ”¹å›¾ç‰‡ä¸­çš„ç‰©ä½“ã€èƒŒæ™¯ã€é¢œè‰²ç­‰
    - å›¾ç‰‡èåˆï¼šç»“åˆå¤šå¼ è¾“å…¥å›¾ç‰‡åˆ›é€ æ–°å†…å®¹
    - å›¾ç‰‡å¢å¼ºï¼šæå‡å›¾ç‰‡è´¨é‡ã€åˆ†è¾¨ç‡ç­‰
    
    æ”¯æŒçš„æ¨¡å‹:
    - gemini-2.5-flash-image-preview: Gemini 2.5 å›¾ç‰‡é¢„è§ˆç¼–è¾‘æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
    - imagen-3.0: Google Imagen 3.0 å›¾ç‰‡ç”Ÿæˆæ¨¡å‹
    - æ”¯æŒé«˜è´¨é‡å›¾ç‰‡ç”Ÿæˆå’Œç¼–è¾‘
    - æ”¯æŒä¸­æ–‡æç¤ºè¯
    
    è¾“å…¥å›¾ç‰‡:
    - image1: ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå¿…é€‰ï¼‰- ä¸»è¦ç¼–è¾‘ç›®æ ‡
    - image2: ç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰- å‚è€ƒæˆ–èåˆç´ æ
    - image3: ç¬¬ä¸‰å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰- å‚è€ƒæˆ–èåˆç´ æ
    - image4: ç¬¬å››å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰- å‚è€ƒæˆ–èåˆç´ æ
    - image5: ç¬¬äº”å¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰- å‚è€ƒæˆ–èåˆç´ æ
    
    ä¾èµ–:
    - pip install requests Pillow numpy torch
    - éœ€é…ç½®ç¯å¢ƒå˜é‡ï¼šDEEPSEEK_API_KEYã€OPENAI_API_KEY æˆ– GOOGLE_API_KEY
    
    æ³¨æ„:
    - å½“å‰é…ç½®ä½¿ç”¨ OpenAI å…¼å®¹ API æ ¼å¼
    - ä¸»è¦è¿”å›å›¾ç‰‡åˆ†æå’Œç¼–è¾‘å»ºè®®æ–‡æœ¬
    - å¦‚éœ€çœŸæ­£çš„å›¾ç‰‡ç”Ÿæˆï¼Œå¯èƒ½éœ€è¦ä¸åŒçš„APIç«¯ç‚¹
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "å°†è¿™å¼ å›¾ç‰‡è½¬æ¢ä¸ºæ²¹ç”»é£æ ¼ï¼Œä¿æŒä¸»è¦å†…å®¹ä¸å˜ï¼Œå¢å¼ºè‰ºæœ¯æ„Ÿå’Œè‰²å½©è¡¨ç°åŠ›"
                }),
                "image1": ("IMAGE", {}),  # ç¬¬ä¸€å¼ å›¾ç‰‡å¿…é€‰
                "model": (["gemini-2.5-flash-image-preview", "imagen-3.0"], {
                    "default": "gemini-2.5-flash-image-preview"
                }),
                "size": (["1024x1024", "512x512", "256x256"], {
                    "default": "1024x1024"
                }),
                "n": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "step": 1,
                    "tooltip": "ç”Ÿæˆå›¾ç‰‡çš„æ•°é‡ (1-4å¼ )"
                }),
            },
            "optional": {
                "image2": ("IMAGE", {}),  # ç¬¬äºŒå¼ å›¾ç‰‡å¯é€‰
                "image3": ("IMAGE", {}),  # ç¬¬ä¸‰å¼ å›¾ç‰‡å¯é€‰
                "image4": ("IMAGE", {}),  # ç¬¬å››å¼ å›¾ç‰‡å¯é€‰
                "image5": ("IMAGE", {}),  # ç¬¬äº”å¼ å›¾ç‰‡å¯é€‰
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647,
                    "step": 1,
                    "tooltip": "éšæœºç§å­ï¼Œ-1ä¸ºè‡ªåŠ¨ç”Ÿæˆ"
                }),
                "max_retries": ("INT", {
                    "default": 2,
                    "min": 0,
                    "max": 5,
                    "step": 1
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING", "BOOLEAN", "INT")
    RETURN_NAMES = ("images", "info", "success", "image_count")
    FUNCTION = "generate"
    CATEGORY = "Google/GenAI"
    OUTPUT_NODE = False

    def generate(self, prompt, image1, model="gemini-2.5-flash-image-preview", size="1024x1024", n=1, 
                 image2=None, image3=None, image4=None, image5=None, seed=-1, max_retries=2):
        
        # å¤„ç†éšæœºç§å­
        if seed == -1:
            seed = random.randint(0, 2147483647)
        
        # è·å– API Key - å°è¯•å¤šä¸ªç¯å¢ƒå˜é‡
        api_key = os.getenv("DEEPSEEK_API_KEY", "").strip() or os.getenv("OPENAI_API_KEY", "").strip() or os.getenv("GOOGLE_API_KEY", "").strip()
        if not api_key:
            return image1, "[Google Imagen Node] æœªæ‰¾åˆ°API Keyï¼Œè¯·è®¾ç½® DEEPSEEK_API_KEYã€OPENAI_API_KEY æˆ– GOOGLE_API_KEY ç¯å¢ƒå˜é‡", False, 0
        
        # å¤„ç†è¾“å…¥å›¾ç‰‡
        input_images = []
        try:
            # å¤„ç†ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå¿…é€‰ï¼‰
            pil_img1 = _comfy_image_to_pil(image1)
            base64_img1 = _pil_to_base64(pil_img1)
            input_images.append(base64_img1)
            
            # å¤„ç†å…¶ä»–å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
            for i, img in enumerate([image2, image3, image4, image5], 2):
                if img is not None:
                    pil_img = _comfy_image_to_pil(img)
                    base64_img = _pil_to_base64(pil_img)
                    input_images.append(base64_img)
                    print(f"[DEBUG] æ·»åŠ ç¬¬{i}å¼ è¾“å…¥å›¾ç‰‡")
            
            print(f"[DEBUG] æ€»å…±å¤„ç†äº† {len(input_images)} å¼ è¾“å…¥å›¾ç‰‡")
            
        except Exception as e:
            return image1, f"[Google Imagen Node] å›¾ç‰‡å¤„ç†å¤±è´¥: {e}", False, 0
        
        # æ„å»º API URL
        #url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateImages"
        url = f"https://www.chataiapi.com/v1/chat/completions"
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºOpenAIå…¼å®¹æ ¼å¼çš„æ¶ˆæ¯
        content_list = [{"type": "text", "text": str(prompt)}]
        
        # æ·»åŠ è¾“å…¥å›¾ç‰‡åˆ°æ¶ˆæ¯å†…å®¹
        for i, img_base64 in enumerate(input_images):
            content_list.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_base64}"
                }
            })
        
        # æ„å»ºè¯·æ±‚è½½è·ï¼ˆOpenAIæ ¼å¼ï¼‰
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": content_list
                }
            ]
        }
        
        # å¦‚æœéœ€è¦seedæ§åˆ¶ï¼ˆAPIæ”¯æŒçš„è¯ï¼‰
        if seed > 0:
            payload["seed"] = seed
        
        print(f"[DEBUG] è°ƒç”¨ Google API - æ¨¡å‹: {model}")
        print(f"[DEBUG] æç¤ºè¯: {prompt[:100]}...")
        print(f"[DEBUG] å‚æ•°: size={size}, n={n}, seed={seed}")
        
        # ç‰¹åˆ«æç¤ºï¼šgemini-2.5-flash-image-preview ä¸»è¦æ˜¯è§†è§‰ç†è§£æ¨¡å‹
        if "gemini" in model.lower() and "preview" in model.lower():
            print(f"[WARNING] æ³¨æ„ï¼š{model} ä¸»è¦æ˜¯è§†è§‰ç†è§£æ¨¡å‹ï¼Œå›¾ç‰‡ç”Ÿæˆèƒ½åŠ›å¯èƒ½æœ‰é™")
        
        # API è°ƒç”¨é‡è¯•é€»è¾‘
        last_error = None
        
        for attempt in range(max_retries + 1):
            try:
                response = requests.post(url, headers=headers, json=payload, timeout=60)
                
                print(f"[DEBUG] APIå“åº”çŠ¶æ€ç : {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"[DEBUG] å“åº”æ•°æ®ç»“æ„: {list(data.keys())}")
                    
                    # è§£æOpenAIæ ¼å¼çš„å“åº”
                    generated_images = []
                    response_text = ""
                    
                    if "choices" in data and data["choices"]:
                        choice = data["choices"][0]
                        message = choice.get("message", {})
                        
                        # è·å–æ–‡æœ¬å“åº”
                        if "content" in message:
                            response_text = message["content"]
                            print(f"[DEBUG] æ¨¡å‹å“åº”æ–‡æœ¬: {response_text[:200]}...")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰reasoning_content
                        if "reasoning_content" in message and message["reasoning_content"]:
                            print(f"[DEBUG] æ‰¾åˆ°æ¨ç†å†…å®¹: {message['reasoning_content'][:100]}...")
                        
                        # æ³¨æ„ï¼šOpenAIèŠå¤©APIé€šå¸¸ä¸ç›´æ¥è¿”å›å›¾ç‰‡ï¼Œä¸»è¦æ˜¯æ–‡æœ¬å“åº”
                        # å¦‚æœè¿™æ˜¯å›¾ç‰‡ç¼–è¾‘APIï¼Œå¯èƒ½éœ€è¦ä¸åŒçš„ç«¯ç‚¹å’Œå“åº”æ ¼å¼
                        print(f"[INFO] è¿™æ˜¯æ–‡æœ¬å“åº”APIï¼Œä¸»è¦è¿”å›åˆ†æç»“æœè€Œä¸æ˜¯ç”Ÿæˆå›¾ç‰‡")
                        
                        # è¿”å›åˆ†æç»“æœï¼Œä½¿ç”¨åŸå›¾ç‰‡
                        return image1, f"ğŸ“ å›¾ç‰‡åˆ†æå®Œæˆ: {response_text}", True, 1
                    
                    else:
                        print(f"[DEBUG] å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ° 'choices' å­—æ®µ")
                        print(f"[DEBUG] å®Œæ•´å“åº”: {data}")
                        return image1, "[Google Imagen Node] API è¿”å›æ ¼å¼å¼‚å¸¸", False, 0
                
                else:
                    error_data = response.text
                    print(f"[DEBUG] APIé”™è¯¯å“åº”: {error_data}")
                    
                    try:
                        error_json = response.json()
                        error_msg = error_json.get("error", {}).get("message", "æœªçŸ¥é”™è¯¯")
                    except:
                        error_msg = f"HTTP {response.status_code}: {error_data[:200]}"
                    
                    last_error = Exception(f"APIé”™è¯¯: {error_msg}")
                    
                    # å¯¹äºæŸäº›é”™è¯¯ä¸é‡è¯•
                    if response.status_code in [400, 401, 403]:
                        break
                        
            except requests.exceptions.Timeout:
                last_error = Exception("è¯·æ±‚è¶…æ—¶")
            except Exception as e:
                last_error = e
                print(f"[DEBUG] è¯·æ±‚å¼‚å¸¸: {e}")
            
            # ç­‰å¾…åé‡è¯•
            if attempt < max_retries:
                import time
                wait_time = (attempt + 1) * 2
                print(f"[DEBUG] ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        # æœ€ç»ˆå¤±è´¥å¤„ç†
        error_str = str(last_error) if last_error else "æœªçŸ¥é”™è¯¯"
        
        if "401" in error_str or "authentication" in error_str.lower():
            error_msg = "[Google Imagen Node] API Key æ— æ•ˆæˆ–æœªæˆæƒï¼Œè¯·æ£€æŸ¥ GOOGLE_API_KEY ç¯å¢ƒå˜é‡"
        elif "quota" in error_str.lower() or "429" in error_str:
            error_msg = "[Google Imagen Node] API é…é¢å·²ç”¨å®Œï¼Œè¯·ç¨åé‡è¯•"
        elif "timeout" in error_str.lower():
            error_msg = "[Google Imagen Node] è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        else:
            error_msg = f"[Google Imagen Node] å›¾ç‰‡ç¼–è¾‘å¤±è´¥: {error_str}"
        
        return image1, error_msg, False, 0


NODE_CLASS_MAPPINGS = {
    "GeminiGenerate": GeminiGenerate,
    "OpenAIGeminiGenerate": OpenAIGeminiGenerate,
    "GoogleImagenGenerate": GoogleImagenGenerate,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiGenerate": "Gemini Generate",
    "OpenAIGeminiGenerate": "OpenAI Gemini Generate", 
    "GoogleImagenGenerate": "Google Gemini Generate",
}

